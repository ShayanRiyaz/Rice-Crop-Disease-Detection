{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "rice-crop-disease-detection-using-tensorflow.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShayanRiyaz/Rice-Crop-Disease-Detection/blob/master/rice-crop-disease-detection-using-tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km2oODYYldxy",
        "colab_type": "text"
      },
      "source": [
        "![Rice Fields](https://github.com/ShayanRiyaz/Rice-Crop-Disease-Detection/blob/master/images/rice-fields.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr5xHU6TtcIc",
        "colab_type": "text"
      },
      "source": [
        "# <div align=\"center\">Rice Crop Disease Detection using TensorFlow</div>\n",
        "<img src=\"https://github.com/ShayanRiyaz/Rice-Crop-Disease-Detection/blob/master/images/TF.png?raw=1\" align = \"right\" width = \"200\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTF4U2wntfNf",
        "colab_type": "text"
      },
      "source": [
        "## Table of Contents\n",
        "- [Importing Libraries](#ImportingLibraries)\n",
        "- [Loading Dataset](#LoadingDataset)\n",
        "- [Resizing Image](#Resize)\n",
        "- [Split into Training and Validation](#Split)\n",
        "- [Image Count](#ImageCount)\n",
        "- [Viewing Images](#ViewingImages)\n",
        "    - [BrownSpot](#BrownSpot)\n",
        "    - [Healthy](#Healthy)\n",
        "    - [Hispa](#Hispa)\n",
        "    - [LeafBlast](#LeafBlast)\n",
        "- [Data Augmentation and Generators](#DataAugAndGen)\n",
        "- [Callback](#Callback)\n",
        "- [Models](#Models)\n",
        "    - [1. Model - Conv2D](#Conv2D)\n",
        "        - [Metrics](#MetricsConv2D)\n",
        "        - [Observing the Convolutions](#ObservingConv2D)\n",
        "    - [2. Model - InceptionV3](#InceptionV3)\n",
        "        - [Metrics](#MetricInceptionv3)\n",
        "    - [3. Model - EfficientNet](#EfficientNet)\n",
        "        - [Metrics](#MetricsEfficientv2)\n",
        "- [Export as TensorFlow LITE](#TFLITE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_SItuPTldx1",
        "colab_type": "text"
      },
      "source": [
        "# Importing Libraries <a name=\"ImportingLibraries\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3RB3td4oldx2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8f4003b6-4aab-4f84-e8bf-c923e6b1f319"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np # linear algebra\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import PIL\n",
        "import cv2\n",
        "\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "from keras import optimizers\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Device:', tpu.master())\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
        "    \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of replicas: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uG_-mWH2ldx7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "79c18638-8191-480e-ff6e-18a9c34d76bc"
      },
      "source": [
        "print(\"Numpy==\",np.__version__)\n",
        "print(\"tensorflow==\", tf.__version__)\n",
        "print(\"pandas==\",pd.__version__)\n",
        "print(\"PIL==\",PIL.__version__)\n",
        "print('matplotlib==',matplotlib.__version__)\n",
        "print('cv2==',cv2.__version__)\n",
        "\n",
        "print(\"tensorflow_hub==\",hub.__version__)\n",
        "print(\"Eager mode:\",tf.executing_eagerly())\n",
        "print(\"GPU is\",\"available\" if tf.test.is_gpu_available() else\"Not Available\")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numpy== 1.18.5\n",
            "tensorflow== 2.3.0\n",
            "pandas== 1.0.5\n",
            "PIL== 7.0.0\n",
            "matplotlib== 3.2.2\n",
            "cv2== 4.1.2\n",
            "tensorflow_hub== 0.8.0\n",
            "Eager mode: True\n",
            "WARNING:tensorflow:From <ipython-input-5-dbe62526865f>:10: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU is Not Available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pza05j_xldx_",
        "colab_type": "text"
      },
      "source": [
        "# Loading Dataset <a name=\"LoadingDataset\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4sYIvz_nldyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/python\n",
        "\n",
        "import os, sys\n",
        "\n",
        "# Create new Train and val folders\n",
        "\n",
        "base_dir = 'kaggle/input/RiceLeafs'\n",
        "train_path = '/kaggle/input/RiceLeafs/train'\n",
        "val_path = 'kaggle/input/RiceLeafs/validation/'\n",
        "\n",
        "column_names = os.listdir(train_path)\n",
        "for i in column_names:\n",
        "    os.makedirs(f'../kaggle/output/train/{i}')\n",
        "    os.makedirs(f'../kaggle/output/validation/{i}')\n",
        "\n",
        "out_path = '../kaggle/output/train/'\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmYIaAeQldyF",
        "colab_type": "text"
      },
      "source": [
        "# Resizing Image <a name=\"Resize\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xr2eKzD1ldyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "def resize(input_path,folder,column_name):\n",
        "    dirs = os.listdir(input_path)\n",
        "    for item in dirs:\n",
        "        item_path = input_path +'/' +item\n",
        "        if os.path.isfile(item_path):\n",
        "            #print('CHECK')\n",
        "            im = Image.open(item_path)\n",
        "\n",
        "            # Check whether the specified \n",
        "            # path exists or not \n",
        "            outpath = f'/kaggle/kaggle/output/{folder}/{column_name}'\n",
        "            temp_out_path = outpath+'/'+item\n",
        "            f, e = os.path.splitext(temp_out_path)\n",
        "\n",
        "            imResize = im.resize((255,255), Image.ANTIALIAS)\n",
        "            #print('CHECK 3')\n",
        "            imResize.save(f + '.jpg', 'JPEG', quality=90)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7qUOHa9MldyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_path = '../input/RiceLeafs/train/Healthy'\n",
        "folder = 'train'\n",
        "column_name = 'Healthy'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "input_path = '../input/RiceLeafs/train/BrownSpot'\n",
        "folder = 'train'\n",
        "column_name = 'BrownSpot'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "input_path = '../input/RiceLeafs/train/Hispa'\n",
        "folder = 'train'\n",
        "column_name = 'Hispa'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "input_path = '../input/RiceLeafs/train/LeafBlast'\n",
        "folder = 'train'\n",
        "column_name = 'LeafBlast'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "print('Done with train resizing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Go6u3w6UldyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## VALIDATION\n",
        "input_path = '../input/RiceLeafs/validation/Healthy'\n",
        "folder = 'validation'\n",
        "column_name = 'Healthy'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "input_path = '../input/RiceLeafs/validation/BrownSpot'\n",
        "folder = 'validation'\n",
        "column_name = 'BrownSpot'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "input_path = '../input/RiceLeafs/validation/Hispa'\n",
        "folder = 'validation'\n",
        "column_name = 'Hispa'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "input_path = '../input/RiceLeafs/validation/LeafBlast'\n",
        "folder = 'validation'\n",
        "column_name = 'LeafBlast'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "print('Done with Validation resizing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1ILvJMF5ldyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.path.exists('/kaggle/kaggle/output/validation/Healthy/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CM-cEwUYldya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.path.exists('/kaggle/kaggle/output/train/')\n",
        "os.path.exists('/kaggle/kaggle/output/validation/')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kCK7uNx_ldyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir('/kaggle/kaggle/output/train/BrownSpot/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HNiuvJJyldyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = os.path.join(os.path.dirname('/kaggle/kaggle/'), 'output')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMAWZejildyk",
        "colab_type": "text"
      },
      "source": [
        "# Split into Training and Validation  <a name=\"Split\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JbNXAqQpldym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use this if you avoided the resizing\n",
        "data_dir = os.path.join(os.path.dirname('/output/'), 'RiceLeafs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Z-nFyDFQldyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(data_dir, 'train')\n",
        "train_BrownSpot_dir = os.path.join(train_dir, 'BrownSpot')\n",
        "train_Healthy_dir = os.path.join(train_dir, 'Healthy')\n",
        "train_Hispa_dir = os.path.join(train_dir, 'Hispa')\n",
        "train_LeafBlast_dir = os.path.join(train_dir, 'LeafBlast')\n",
        "\n",
        "\n",
        "validation_dir = os.path.join(data_dir, 'validation')\n",
        "validation_BrownSpot_dir = os.path.join(validation_dir, 'BrownSpot')\n",
        "validation_Healthy_dir = os.path.join(validation_dir, 'Healthy')\n",
        "validation_Hispa_dir = os.path.join(validation_dir, 'Hispa')\n",
        "validation_LeafBlast_dir = os.path.join(validation_dir, 'LeafBlast')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Zv0fPaOcldyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_BrownSpot_names = os.listdir(train_BrownSpot_dir)\n",
        "print(train_BrownSpot_names[:10])\n",
        "\n",
        "train_Healthy_names =  os.listdir(train_Healthy_dir)\n",
        "print(train_Healthy_names[:10])\n",
        "\n",
        "train_Hispa_names = os.listdir(train_Hispa_dir)\n",
        "print(train_Hispa_names[:10])\n",
        "\n",
        "train_LeafBlast_names =  os.listdir(train_LeafBlast_dir)\n",
        "print(train_LeafBlast_names[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apnVwz6Vldyx",
        "colab_type": "text"
      },
      "source": [
        "## Image Count <a name=\"ImageCount\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GEdwoIu-ldyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import time\n",
        "import os\n",
        "from os.path import exists\n",
        "\n",
        "def count(dir, counter=0):\n",
        "    \"returns number of files in dir and subdirs\"\n",
        "    for pack in os.walk(dir):\n",
        "        for f in pack[2]:\n",
        "            counter += 1\n",
        "    return dir + \" : \" + str(counter) + \" files\"\n",
        "\n",
        "print('total images for training :', count(train_dir))\n",
        "print('total images for validation :', count(validation_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkXT_l06ldy2",
        "colab_type": "text"
      },
      "source": [
        "## Viewing Images  <a name=\"ViewingImages\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "x54nxsHxldy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters for our graph; we'll outpu images in a 4x4 configuration\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "# for iternating over images\n",
        "pic_index = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0q3Dra_ldy6",
        "colab_type": "text"
      },
      "source": [
        "### BrownSpot <a name=\"BrownSpot\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YESimJhqldy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols *4, nrows*4)\n",
        "\n",
        "pic_index += 8\n",
        "next_BrownSpot_pix = [os.path.join(train_BrownSpot_dir, fname)\n",
        "                for fname in train_BrownSpot_names[pic_index-8:pic_index]]\n",
        "for i, img_path in enumerate(next_BrownSpot_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows,ncols,i +1)\n",
        "  #sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t30YoHUqldy-",
        "colab_type": "text"
      },
      "source": [
        "### Healthy <a name=\"Healthy\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XL2VEBL-ldy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols *4, nrows*4)\n",
        "\n",
        "pic_index += 8\n",
        "next_Healthy_pix = [os.path.join(train_Healthy_dir, fname)\n",
        "                for fname in train_Healthy_names[pic_index-8:pic_index]]\n",
        "\n",
        "\n",
        "for i, img_path in enumerate(next_Healthy_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows,ncols,i +1)\n",
        "  #sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxw4PHmVldzC",
        "colab_type": "text"
      },
      "source": [
        "### Hispa <a name=\"Hispa\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jdduhyGaldzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols *4, nrows*4)\n",
        "\n",
        "pic_index += 8\n",
        "\n",
        "next_Hispa_pix = [os.path.join(train_Hispa_dir, fname)\n",
        "                for fname in train_Hispa_names[pic_index-8:pic_index]]\n",
        "\n",
        "\n",
        "for i, img_path in enumerate(next_Hispa_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows,ncols,i +1)\n",
        "  #sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoTr48FOldzG",
        "colab_type": "text"
      },
      "source": [
        "### LeafBlast <a name=\"LeafBlast\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CKPeYwXKldzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols *4, nrows*4)\n",
        "\n",
        "pic_index += 8\n",
        "\n",
        "next_LeafBlast_pix = [os.path.join(train_LeafBlast_dir, fname)\n",
        "                for fname in train_LeafBlast_names[pic_index-8:pic_index]]\n",
        "\n",
        "for i, img_path in enumerate(next_LeafBlast_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows,ncols,i +1)\n",
        "  #sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulLPfmF-ldzK",
        "colab_type": "text"
      },
      "source": [
        "# Data Augmentation and Generators <a name=\"DataAugAndGen\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "d83ia2PvldzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SHAPE = (244, 244)\n",
        "BATCH_SIZE = 64 #@param {type:\"integer\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9VUEnV9hldzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inputs are suitably resized for the selected module. Dataset augmentation (i.e., random distortions of an image each time it is read) improves training, esp. when fine-tuning.\n",
        "\n",
        "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir, \n",
        "    shuffle=False, \n",
        "    seed=42,\n",
        "    color_mode=\"rgb\", \n",
        "    class_mode=\"categorical\",\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "do_data_augmentation = True #@param {type:\"boolean\"}\n",
        "if do_data_augmentation:\n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      rotation_range=40,\n",
        "      horizontal_flip=True,\n",
        "      width_shift_range=0.2, \n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2, \n",
        "      zoom_range=0.2,\n",
        "      fill_mode='nearest' )\n",
        "else:\n",
        "  train_datagen = validation_datagen\n",
        "  \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,  \n",
        "    shuffle=True, \n",
        "    seed=42,\n",
        "    color_mode=\"rgb\", \n",
        "    class_mode=\"categorical\",\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "u0OH89_2ldzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator.num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haVGz4S1ldzU",
        "colab_type": "text"
      },
      "source": [
        "## Callback <a name=\"Callback\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ahWJYkcGldzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self,epoch,log = {}):\n",
        "    if(log.get('accuracy')> 0.99):\n",
        "      if(log.get('val_accuracy')>0.99):\n",
        "        print(\"\\n Reached 99% Accuracy for both train and val.\")\n",
        "        self.model.stop_training = True\n",
        "\n",
        "callbacks = MyCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gir_Xihdldza",
        "colab_type": "text"
      },
      "source": [
        "# Models <a name=\"Model\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olGFzMDpldzb",
        "colab_type": "text"
      },
      "source": [
        "### 1. Model - Conv2D <a name=\"Conv2D\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JVwH8frAldzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(16,(3,3),activation = 'relu',input_shape = (244,244,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32,(3,3),activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128,activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(256,activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(4,activation = 'softmax')\n",
        "\n",
        "],    name = 'Conv2D_Model')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uxFc2nCDldzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 0.001 #@param {type:\"number\"}\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Uf0OJdcvldzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS=10 #@param {type:\"integer\"}\n",
        "\n",
        "history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks = [callbacks],\n",
        "        validation_steps=validation_generator.samples//validation_generator.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2vvkP39ldzl",
        "colab_type": "text"
      },
      "source": [
        "### Metrics <a name=\"MetricsConv2D\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "94DR-8QAldzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOpOZxDmldzo",
        "colab_type": "text"
      },
      "source": [
        "#### Observing the Convolutions  <a name=\"ObservingConv2D\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HneYECs7ldzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "\n",
        "# Lets define a new Model that will take an image as an input and will output \n",
        "# the intermediate representations for all layers in the previous model after \n",
        "# the first\n",
        "\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "\n",
        "# Visualization_model = Model(img_input,successive_outputs)\n",
        "visualization_model = tf.keras.models.Model(inputs = model.input,\n",
        "                                            outputs = successive_outputs)\n",
        "\n",
        "# Lets prepare a random input image form the training set.\n",
        "\n",
        "BrownSpot_img_files = [os.path.join(train_BrownSpot_dir, f) for f in train_BrownSpot_names]\n",
        "Healthy_files = [os.path.join(train_Healthy_dir, f) for f in train_Healthy_names]\n",
        "img_path = random.choice(BrownSpot_img_files + Healthy_files)\n",
        "\n",
        "\n",
        "img = load_img(img_path,target_size = (244,244)) # This is a PIL image\n",
        "x = img_to_array(img)  # Numpy array with shape (244,244,3)\n",
        "x = x.reshape((1,) + x.shape) # Numpy array with shape (1,244,244,3)\n",
        "\n",
        "# Rescale by 1/255\n",
        "x /=255\n",
        "\n",
        "\n",
        "# Let's run our image through our network, thus obtaining all\n",
        "# Intermediate representations for this image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# These are the names of the layers so we can have them as part of our plot\n",
        "layer_names = [layer.name for layer in model.layers[1:]]\n",
        "\n",
        "\n",
        "# Now lets display our representations\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  if len(feature_map.shape) == 4:\n",
        "    # Just do this for the conv/maxpool layers, for the fully-connected layers\n",
        "    n_features = feature_map.shape[-1] # number of features in feature map\n",
        "    # The feature map has shape (1,size,size,n_features)\n",
        "    size = feature_map.shape[1]\n",
        "    # We will title our images in this matrix\n",
        "    display_grid = np.zeros((size, size* n_features))\n",
        "    for i in range(n_features):\n",
        "      # Post process the feature to make it visibly palatable\n",
        "      x = feature_map[0,:,:,i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std()\n",
        "      x *= 64\n",
        "      x+= 128\n",
        "      x = np.clip(x,0,255).astype('uint8')\n",
        "      # We'll tile each filter into this big horizontal grid\n",
        "      display_grid[:,i*size:(i+1)*size] = x\n",
        "    # Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure(figsize=(scale*n_features,scale))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid,aspect = 'auto', cmap = 'viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTh0LKTDldzt",
        "colab_type": "text"
      },
      "source": [
        "### 2.Model - Inception <a name=\"InceptionV3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2V7J5vDldzu",
        "colab_type": "text"
      },
      "source": [
        "#### Downloading Weights <a name=\"DownloadWeights\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-GTgVPxHldzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf.dim_ordering_tf_kernels.notop.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "V2iHupfhldzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf.dim_ordering_tf_kernels.notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(\n",
        "                                input_shape = (244,244,3),\n",
        "                                include_top= False,\n",
        "                                weights = None\n",
        ")\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FfgUDGZrldz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print(f'The shape of the last layer is {last_layer.output_shape}')\n",
        "output_layer = last_layer.output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "B7vvnKHYldz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "x = tf.keras.layers.Flatten()(output_layer)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.4)(x)\n",
        "#x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x,name=\"RiceLeafs_Inception_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tTCSKx5Xldz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 0.001 #@param {type:\"number\"}\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr = LEARNING_RATE),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5aCgYqlAld0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS=10 #@param {type:\"integer\"}\n",
        "\n",
        "history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks = [callbacks],\n",
        "        validation_steps=validation_generator.samples//validation_generator.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtd0WkGvld0E",
        "colab_type": "text"
      },
      "source": [
        "#### Metrics <a name=\"MetricsInceptionv3\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MqrzQYnFld0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h24EInWKld0I",
        "colab_type": "text"
      },
      "source": [
        "### 3. Model - EfficientNet v2 <a name=\"EfficientNet\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1FlTgJSld0J",
        "colab_type": "text"
      },
      "source": [
        "#### TensorFlow Hub Dataset\n",
        "- [EfficientNet B7](https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kKpc5Orbld0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "model = tf.keras.Sequential([\n",
        "hub.KerasLayer(\"https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1\"),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "\n",
        "  tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.build([None, 244, 244, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "imu37cFmld0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile model specifying the optimizer learning rate\n",
        "\n",
        "LEARNING_RATE = 0.0001 #@param {type:\"number\"}\n",
        "\n",
        "model.compile(\n",
        "   optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE), \n",
        "   loss='categorical_crossentropy',\n",
        "   metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_fTuA8oRld0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS=10 #@param {type:\"integer\"}\n",
        "\n",
        "history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=validation_generator,\n",
        "        #callbacks = [callbacks],\n",
        "        validation_steps=validation_generator.samples//validation_generator.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v458UNFld0U",
        "colab_type": "text"
      },
      "source": [
        "### Metrics <a name=\"MetricsEfficientv2\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZnRtOJusld0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmSLW28sld0a",
        "colab_type": "text"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OnDxOixcld0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SHAPE[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2JZ2ZLbXld0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import OpenCV\n",
        "import cv2\n",
        "\n",
        "# Utility\n",
        "import itertools\n",
        "import random\n",
        "from collections import Counter\n",
        "from glob import iglob\n",
        "\n",
        "\n",
        "def load_image(filename):\n",
        "    img = cv2.imread(os.path.join(data_dir, validation_dir, filename))\n",
        "    img = cv2.resize(img,(IMAGE_SHAPE[0], IMAGE_SHAPE[1]) )\n",
        "    img = img /255\n",
        "    \n",
        "    return img\n",
        "\n",
        "\n",
        "def predict(image):\n",
        "    probabilities = model.predict(np.asarray([img]))[0]\n",
        "    class_idx = np.argmax(probabilities)\n",
        "    \n",
        "    return {classes[class_idx]: probabilities[class_idx]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "U6ULe1gold0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx, filename in enumerate(random.sample(validation_generator.filenames, 5)):\n",
        "    print(\"SOURCE: class: %s, file: %s\" % (os.path.split(filename)[0], filename))\n",
        "    \n",
        "    img = load_image(filename)\n",
        "    prediction = predict(img)\n",
        "    print(\"PREDICTED: class: %s, confidence: %f\" % (list(prediction.keys())[0], list(prediction.values())[0]))\n",
        "    plt.imshow(img)\n",
        "    plt.figure(idx)    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI0gxAH5ld0l",
        "colab_type": "text"
      },
      "source": [
        "# Export as TensorFlowLITE <a name=\"TFLITE\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ulWB1yi-ld0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "t = time.time()\n",
        "\n",
        "export_path = \"/tmp/saved_models/{}\".format(int(t))\n",
        "tf.keras.experimental.export_saved_model(model, export_path)\n",
        "\n",
        "export_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Bs9ZGIELld0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now confirm that we can reload it, and it still gives the same results\n",
        "reloaded = tf.keras.experimental.load_from_saved_model(export_path, custom_objects={'KerasLayer':hub.KerasLayer}) # custom_objects depends on model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cPezK8uXld0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the model to TFLite\n",
        "!mkdir \"tflite_models\"\n",
        "TFLITE_MODEL = \"tflite_models/rice_leaf_disease.tflite\"\n",
        "\n",
        "\n",
        "# Get the concrete function from the Keras model.\n",
        "run_model = tf.function(lambda x : reloaded(x))\n",
        "\n",
        "# Save the concrete function.\n",
        "concrete_func = run_model.get_concrete_function(\n",
        "    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype)\n",
        ")\n",
        "\n",
        "# Convert the model to standard TensorFlow Lite model\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "converted_tflite_model = converter.convert()\n",
        "open(TFLITE_MODEL, \"wb\").write(converted_tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}